{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\n\nfrom sklearn.datasets import make_blobs\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.inspection import DecisionBoundaryDisplay\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n\n\ncolumn_names = ['Time', \n                'Ankle_h_fwd_acc', 'Ankle_v_acc', 'Ankle_h_lat_acc',\n                'thigh_h_fwd_acc', 'thigh_v_acc', 'thigh_h_lat_acc',\n                'trunk_h_fwd_acc', 'trunk_v_acc', 'trunk_h_lat_acc',\n                'annotation']\n\nurl = '/kaggle/input/freezing-of-gait/FOG/freezing-of-gait-exploration-main/freezing-of-gait-exploration-main/dataset_fog_release/dataset'\nfilenames = ['/S01R01.txt', '/S01R02.txt', '/S02R01.txt', '/S02R02.txt', '/S03R01.txt', '/S03R02.txt', '/S03R03.txt',\n             '/S04R01.txt', '/S05R01.txt', '/S05R02.txt', '/S06R01.txt', '/S06R02.txt', '/S07R01.txt', '/S07R02.txt',\n             '/S08R01.txt', '/S09R01.txt', '/S10R01.txt']\n\n# Split file names into two parts\nfiles_part1 = filenames[:14]\nfiles_part2 = filenames[14:17]\n","metadata":{"execution":{"iopub.status.busy":"2023-07-22T14:19:33.006462Z","iopub.execute_input":"2023-07-22T14:19:33.006985Z","iopub.status.idle":"2023-07-22T14:19:35.924097Z","shell.execute_reply.started":"2023-07-22T14:19:33.006948Z","shell.execute_reply":"2023-07-22T14:19:35.922859Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import cross_val_score, StratifiedKFold\n\nrows = []\nfor i in files_part1: \n    with open(url+i, 'r') as file:\n        text_dataset = file.read()\n    rows = rows + text_dataset.strip().split('\\n')\ndf = pd.DataFrame([row.split() for row in rows])\ndf.columns = column_names\ndf.columns = column_names","metadata":{"execution":{"iopub.status.busy":"2023-07-22T14:19:35.928982Z","iopub.execute_input":"2023-07-22T14:19:35.929596Z","iopub.status.idle":"2023-07-22T14:19:43.290267Z","shell.execute_reply.started":"2023-07-22T14:19:35.929560Z","shell.execute_reply":"2023-07-22T14:19:43.289314Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"X = df.drop(\"annotation\", axis = 1)                  # Apply drop() function\ny = df.drop(column_names[:-1], axis=1)\ny = np.array(y).ravel()","metadata":{"execution":{"iopub.status.busy":"2023-07-22T14:19:43.291818Z","iopub.execute_input":"2023-07-22T14:19:43.292187Z","iopub.status.idle":"2023-07-22T14:19:43.671786Z","shell.execute_reply.started":"2023-07-22T14:19:43.292153Z","shell.execute_reply":"2023-07-22T14:19:43.670805Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import cross_val_score, StratifiedKFold\n\n# Assuming you have the necessary imports and 'files_part2' defined\n\nrows_part1 = []\nfor i in files_part1: \n    with open(url+i, 'r') as file:\n        text_dataset = file.read()\n    rows_part1 = rows_part1 + text_dataset.strip().split('\\n')\ndf_part1 = pd.DataFrame([row.split() for row in rows_part1])\ndf_part1.columns = column_names\n\nrows_part2 = []\nfor i in files_part2: \n    with open(url+i, 'r') as file:\n        text_dataset = file.read()\n    rows_part2 = rows_part2 + text_dataset.strip().split('\\n')\ndf_part2 = pd.DataFrame([row.split() for row in rows_part2])\ndf_part2.columns = column_names\n\nX_train = df_part1.drop(\"annotation\", axis=1)\ny_train = df_part1[\"annotation\"]\n\nX_val = df_part2.drop(\"annotation\", axis=1)\ny_val = df_part2[\"annotation\"]\n\n# Create the classifier object\nknn = KNeighborsClassifier(n_neighbors=7)\n\n# Create the StratifiedKFold object\nskf = StratifiedKFold(n_splits=5, random_state=42, shuffle=True)\n\n# Perform 5-fold cross-validation on the training set\nscores = cross_val_score(knn, X_train, y_train, cv=skf)\n\n# Print the scores for each fold\nfor fold, score in enumerate(scores, start=1):\n    print(f\"Fold {fold}: {score}\")\n\n# Calculate the mean score across all folds\nmean_score = scores.mean()\nprint(\"Mean Score:\", mean_score)\n\n","metadata":{"execution":{"iopub.status.busy":"2023-07-22T14:19:43.674223Z","iopub.execute_input":"2023-07-22T14:19:43.674589Z","iopub.status.idle":"2023-07-22T14:21:51.091821Z","shell.execute_reply.started":"2023-07-22T14:19:43.674559Z","shell.execute_reply":"2023-07-22T14:21:51.090669Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Fold 1: 0.9724161801530707\nFold 2: 0.9723314155338229\nFold 3: 0.9724974129131834\nFold 4: 0.9726704740108145\nFold 5: 0.9727339511754068\nMean Score: 0.9725298867572597\n","output_type":"stream"}]},{"cell_type":"code","source":"# Train on the entire training set and validate on the separate validation set\nknn.fit(X_train, y_train)\ny_pred = knn.predict(X_val)\n\n# Calculate the validation accuracy\nval_accuracy = accuracy_score(y_val, y_pred)\nprint(\"Validation Accuracy:\", val_accuracy)\n# Calculate the validation precision\nprecision = precision_score(y_val, y_pred, average='weighted')\n\n# Calculate the validation F1 score\nf1 = f1_score(y_val, y_pred, average='weighted')\n\n# Print the validation precision and F1 score\nprint('Validation Precision:', precision)\nprint('Validation F1 Score:', f1)","metadata":{"execution":{"iopub.status.busy":"2023-07-22T14:21:51.093450Z","iopub.execute_input":"2023-07-22T14:21:51.094084Z","iopub.status.idle":"2023-07-22T14:22:47.721044Z","shell.execute_reply.started":"2023-07-22T14:21:51.094048Z","shell.execute_reply":"2023-07-22T14:22:47.719900Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Validation Accuracy: 0.6713500317600651\nValidation Precision: 0.6771863315360674\nValidation F1 Score: 0.6679019569291367\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.model_selection import cross_val_score, StratifiedKFold\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n# Assuming you have the necessary imports and 'files_part2' defined\n\nrows_part1 = []\nfor i in filenames: \n    with open(url+i, 'r') as file:\n        text_dataset = file.read()\n    rows_part1 = rows_part1 + text_dataset.strip().split('\\n')\ndf_part1 = pd.DataFrame([row.split() for row in rows_part1])\ndf_part1.columns = column_names\n\nX_train = df_part1.drop(\"annotation\", axis=1)\ny_train = df_part1[\"annotation\"]\n\n\n# Create the classifier object\nknn = KNeighborsClassifier(n_neighbors=7)\n\n# Create the StratifiedKFold object\nskf = StratifiedKFold(n_splits=5, random_state=42, shuffle=True)\n\n# Perform 5-fold cross-validation on the training set\nscores = cross_val_score(knn, X_train, y_train, cv=skf)\n\nmetrics_dict = {'Accuracy': [], 'Precision': [], 'F1 Score': []}\n\n# Perform cross-validation and collect the metrics for each fold\nfor fold, (train_index, test_index) in enumerate(skf.split(X_train, y_train), start=1):\n    X_train_fold, X_test_fold = X_train.iloc[train_index], X_train.iloc[test_index]\n    y_train_fold, y_test_fold = y_train.iloc[train_index], y_train.iloc[test_index]\n    \n    # Fit the classifier to the training fold\n    knn.fit(X_train_fold, y_train_fold)\n    \n    # Predict on the test fold\n    y_pred_fold = knn.predict(X_test_fold)\n    \n    # Calculate and store the metrics for the fold\n    accuracy = accuracy_score(y_test_fold, y_pred_fold)\n    precision = precision_score(y_test_fold, y_pred_fold, average='weighted')\n    f1 = f1_score(y_test_fold, y_pred_fold, average='weighted')\n    \n    metrics_dict['Accuracy'].append(accuracy)\n    metrics_dict['Precision'].append(precision)\n    metrics_dict['F1 Score'].append(f1)\n    \n    # Print the metrics for the fold\n    print(f\"Fold {fold}:\")\n    print(f\"Accuracy: {accuracy}\")\n    print(f\"Precision: {precision}\")\n    print(f\"F1 Score: {f1}\")\n    print()\n    \n# Calculate the mean scores across all folds\nmean_accuracy = sum(metrics_dict['Accuracy']) / len(metrics_dict['Accuracy'])\nmean_precision = sum(metrics_dict['Precision']) / len(metrics_dict['Precision'])\nmean_f1 = sum(metrics_dict['F1 Score']) / len(metrics_dict['F1 Score'])\n\n# Print the mean scores\nprint(\"Mean Accuracy:\", mean_accuracy)\nprint(\"Mean Precision:\", mean_precision)\nprint(\"Mean F1 Score:\", mean_f1)\n","metadata":{"execution":{"iopub.status.busy":"2023-07-22T14:22:47.723805Z","iopub.execute_input":"2023-07-22T14:22:47.724491Z","iopub.status.idle":"2023-07-22T14:29:11.692920Z","shell.execute_reply.started":"2023-07-22T14:22:47.724449Z","shell.execute_reply":"2023-07-22T14:29:11.691694Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Fold 1:\nAccuracy: 0.9733039955367617\nPrecision: 0.9728507802978912\nF1 Score: 0.9729589004827524\n\nFold 2:\nAccuracy: 0.9731892861425838\nPrecision: 0.9727145125705786\nF1 Score: 0.9728204129427671\n\nFold 3:\nAccuracy: 0.9729441546286665\nPrecision: 0.9724576730588136\nF1 Score: 0.9725627449008549\n\nFold 4:\nAccuracy: 0.9723419287392101\nPrecision: 0.9718536527825495\nF1 Score: 0.9719731942847996\n\nFold 5:\nAccuracy: 0.9727069141267595\nPrecision: 0.9722411225020472\nF1 Score: 0.9723561979076295\n\nMean Accuracy: 0.9728972558347962\nMean Precision: 0.972423548242376\nMean F1 Score: 0.9725342901037607\n","output_type":"stream"}]},{"cell_type":"code","source":"# Read data from files in files_part2\nrows_part2 = []\nfor i in files_part2: \n    with open(url + i, 'r') as file:\n        text_dataset = file.read()\n    rows_part2 = rows_part2 + text_dataset.strip().split('\\n')\ndf_part2 = pd.DataFrame([row.split() for row in rows_part2])\ndf_part2.columns = column_names\n\n# Preprocess the data in df_part2 (handle missing values, convert columns to numeric types, etc.)\n\n# Split DataFrame into features (X_test) and labels (y_test)\nX_test = df_part2.drop(\"annotation\", axis=1)\ny_test = df_part2[\"annotation\"]\n\n# Use the trained KNN model to predict on X_test\ny_pred_test = knn.predict(X_test)\n\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n\n# Calculate the test accuracy\ntest_accuracy = accuracy_score(y_test, y_pred_test)\nprint(\"Test Accuracy:\", test_accuracy)\n\n# Calculate the confusion matrix\nconf_matrix = confusion_matrix(y_test, y_pred_test)\n\n# Calculate the true positive, true negative, false positive, and false negative values from the confusion matrix\nTP = conf_matrix[1, 1]\nTN = conf_matrix[0, 0]\nFP = conf_matrix[0, 1]\nFN = conf_matrix[1, 0]\n\n# Calculate Sensitivity (True Positive Rate) and Specificity (True Negative Rate)\nsensitivity = TP / (TP + FN)\nspecificity = TN / (TN + FP)\n\n# Calculate Precision (Positive Predictive Value) and Negative Predictive Value\nprecision = precision_score(y_test, y_pred_test, average='weighted')\nnegative_predictive_value = TN / (TN + FN)\n\n# Calculate Fall out (False Positive Rate) and False Negative Rate\nfalse_positive_rate = FP / (FP + TN)\nfalse_negative_rate = FN / (TP + FN)\n\n# Calculate F1 Score\nf1 = f1_score(y_test, y_pred_test, average='weighted')\n\n# Print the metrics\nprint(\"Sensitivity (True Positive Rate):\", sensitivity)\nprint(\"Specificity (True Negative Rate):\", specificity)\nprint(\"Precision (Positive Predictive Value):\", precision)\nprint(\"Negative Predictive Value:\", negative_predictive_value)\nprint(\"Fall out (False Positive Rate):\", false_positive_rate)\nprint(\"False Negative Rate:\", false_negative_rate)\nprint(\"F1 Score:\", f1)","metadata":{"execution":{"iopub.status.busy":"2023-07-22T14:29:11.694568Z","iopub.execute_input":"2023-07-22T14:29:11.694956Z","iopub.status.idle":"2023-07-22T14:29:56.506870Z","shell.execute_reply.started":"2023-07-22T14:29:11.694921Z","shell.execute_reply":"2023-07-22T14:29:56.505640Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Test Accuracy: 0.9886918238242305\nSensitivity (True Positive Rate): 0.9950493048077241\nSpecificity (True Negative Rate): 0.9956429426740055\nPrecision (Positive Predictive Value): 0.9886242003861324\nNegative Predictive Value: 0.9932392754430609\nFall out (False Positive Rate): 0.004357057325994425\nFalse Negative Rate: 0.004950695192275887\nF1 Score: 0.9886395191800952\n","output_type":"stream"}]}]}